install.packages("FactoMineR", dependencies = TRUE)
install.packages("xlsx", repos = "http://cran.cnr.Berkeley.edu/")
install.packages("xlsx", repos = "http://cran.cnr.Berkeley.edu/")
install.packages("FactoMineR", dependencies = TRUE)
install.packages("openxlsx", dependencies=TRUE)
install.packages("FactoMineR", dependencies = TRUE)
install.packages("openxlsx", dependencies=TRUE)
library(installr)
install.packages("installr")
install.packages('openxlsx', type='source', repos='http://cran.rstudio.com')
var(5,4)
var(c(5,4))
var(c(2,1,6,2,5,1,1,1,2,2,1,5,4,1,1,1,1,3))
sd(c(2,1,6,2,5,1,1,1,2,2,1,5,4,1,1,1,1,3))
mean(c(2,1,6,2,5,1,1,1,2,2,1,5,4,1,1,1,1,3))
sd(c(2,1,6,2,5,1,1,1,2,2,1,5,4,1,1,1,1,3))
median(c(2,1,6,2,5,1,1,1,2,2,1,5,4,1,1,1,1,3))
install.packages("NMF", dependencies = TRUE)
install.packages("skmeans", dependencies = TRUE)
library(skmeans)
library(NMF)
install.packages("NMF", dependencies = TRUE)
install.packages("NMF", dependencies = TRUE)
library(NMF)
install.packages("NMF", dependencies = TRUE)
install.packages("NMF", dependencies = TRUE)
install.packages("openssl", dependencies = TRUE)
install.packages("NMF", dependencies = TRUE)
install.packages("Rmpi", dependencies = TRUE)
install.packages("Biobase", dependencies = TRUE)
clear
clear()
install.packages("NMF", dependencies = TRUE)
install.packages("doMPI", dependencies = TRUE)
install.packages("Rmpi", dependencies = TRUE)
install.packages("Rmpi", dependencies = TRUE)
install.packages("NMF", dependa)
install.packages("Rmpi", dependencies = TRUE)
install.packages("NMF", dependencies = TRUE)
library("NMF")
library("skmeans")
install.extras('NMF')
library(pixmap)
read.pnm('MtRush.pgm')
matrix(1:27, nrow = 4, ncol = 4)
matrix(1:27, ncol = 5)
matrix(1:30, ncol = 5)
x <- matrix(1:30, ncol = 5)
x
nmf(x, 3)
res <- nmf(x, 3)
res
?nmf
res
res@fit
res@fit@W
res@fit@H
x
res <- nmf(x, 1)
res
res <- nmf(x, 5)
res
res@fit@W
res <- nmf(x, 3)
getwd()
readMat("sparse_data.mat")
library("matlab")
install.packages("matlab")
library(matlab)
install.packages("matlab", dependencies = TRUE)
install.packages("matlab", dependencies = TRUE)
library(matlab)
install.packages("R.matlab", dependencies = TRUE)
library(R.matlab)
readMat("sparse_data.mat")
x <- readMat("sparse_data.mat")
x
library(R.matlab)
readMat("sparse_data.mat")
x <- readMat("sparse_data.mat")
x
library(keras)
install.packages(keras, dependencies = TRUE)
install.packages("keras", dependencies = TRUE)
library(keras)
library(rARPACK) # to use SVDS
install.packages("rARPACK", dependencies = TRUE)
library(keras)
library(rARPACK) # to use SVDS
library(keras)
library(rARPACK) # to use SVDS
rm(list=ls())
mnist   = dataset_mnist()
install_keras()
mnist   = dataset_mnist()
x_train = mnist$train$x
y_train = mnist$train$y
x_test  = mnist$test$x
y_test  = mnist$test$y
# reshape & rescale
dim(x_train) = c(nrow(x_train), 784)
dim(x_test)  = c(nrow(x_test), 784)
x_train = x_train / 255
x_test = x_test / 255
mus = colMeans(x_train)
x_train_c =  sweep(x_train, 2, mus)
x_test_c =  sweep(x_test, 2, mus)
digitSVDS = svds(x_train_c, k = 2)
ZpcaTEST = x_test_c %*% digitSVDS$v # PCA projection of test data
model = keras_model_sequential()
model %>%
layer_dense(units = 512, activation = 'elu', input_shape = c(784)) %>%
layer_dense(units = 128, activation = 'elu') %>%
layer_dense(units = 2,   activation = 'linear', name = "bottleneck") %>%
layer_dense(units = 128, activation = 'elu') %>%
layer_dense(units = 512, activation = 'elu') %>%
layer_dense(units = 784, activation='sigmoid')
model %>% compile(
loss = loss_mean_squared_error, optimizer = optimizer_adam())
history = model %>% fit(verbose = 2, validation_data = list(x_test, x_test),
x_train, x_train, epochs = 5, batch_size = 128)
# Set the auto-encoder
autoencoder = keras_model(model$input, model$get_layer('bottleneck')$output)
ZencTEST = autoencoder$predict(x_test)  # bottleneck representation  of test data
par(mfrow=c(1,2))
myCols = colorRampPalette(c('green',     'red',  'blue',  'orange', 'steelblue2',
'darkgreen', 'cyan', 'black', 'grey',   'magenta') )
plot(ZpcaTEST[1:5000,], col= myCols(10)[(y_test+1)],
pch=16, xlab = 'Score 1', ylab = 'Score 2', main = 'PCA' )
legend( 'bottomright', col= myCols(10), legend = seq(0,9, by=1), pch = 16 )
plot(ZencTEST[1:5000,], col= myCols(10)[(y_test+1)],
pch=16, xlab = 'Score 1', ylab = 'Score 2', main = 'Autoencoder' )
legend( 'bottomleft', col= myCols(10), legend = seq(0,9, by=1), pch = 16 )
Renc = predict(model, x_test)        # autoencoder reconstruction
Rpca = sweep( ZpcaTEST %*% t(digitSVDS$v), 2, -mus) # PCA reconstruction
dev.off()
par(mfcol=c(3,9), mar = c(1, 1, 0, 0))
myGrays = gray(1:256 / 256)
for(u in seq_len(9) ){
image( matrix( x_test[u,], 28,28, byrow = TRUE)[,28:1], col = myGrays,
xaxt='n', yaxt='n')
image( matrix( Rpca[u,], 28,28, byrow = TRUE)[,28:1], col = myGrays ,
xaxt='n', yaxt='n')
image( matrix( Renc[u,], 28,28, byrow = TRUE)[,28:1], col = myGrays,
xaxt='n', yaxt='n')
}
history = model %>% fit(verbose = 2, validation_data = list(x_test, x_test),
x_train, x_train, epochs = 50, batch_size = 128)
# Set the auto-encoder
autoencoder = keras_model(model$input, model$get_layer('bottleneck')$output)
ZencTEST = autoencoder$predict(x_test)  # bottleneck representation  of test data
par(mfrow=c(1,2))
myCols = colorRampPalette(c('green',     'red',  'blue',  'orange', 'steelblue2',
'darkgreen', 'cyan', 'black', 'grey',   'magenta') )
plot(ZpcaTEST[1:5000,], col= myCols(10)[(y_test+1)],
pch=16, xlab = 'Score 1', ylab = 'Score 2', main = 'PCA' )
legend( 'bottomright', col= myCols(10), legend = seq(0,9, by=1), pch = 16 )
plot(ZencTEST[1:5000,], col= myCols(10)[(y_test+1)],
pch=16, xlab = 'Score 1', ylab = 'Score 2', main = 'Autoencoder' )
legend( 'bottomleft', col= myCols(10), legend = seq(0,9, by=1), pch = 16 )
Renc = predict(model, x_test)        # autoencoder reconstruction
Rpca = sweep( ZpcaTEST %*% t(digitSVDS$v), 2, -mus) # PCA reconstruction
# Experiment
kmeans(x_train)
# Experiment
kmeans(x_train, 10)
# Experiment
res <- kmeans(x_train, 10)
# Experiment
res <- kmeans(x_train, 10)
res
install.packages("e1071", dependencies = TRUE)
install.packages("e1071", dependencies = TRUE)
install.packages("e1071", dependencies = TRUE)
install.packages("e1071", dependencies = TRUE)
library("e1071")
c <- rep(-1, times = 5)
c
c <- c(rep(-1, times = 5), rep(1, times = 5))
c
c <- c(rep(-1, times = 5), rep(1, times = 5))
x1 <- c(1, 2, 4, 6, 8, 5, 7, 9, 12, 13)
x2 <- c(3,1,5,9,7,1,1,4,7,6)
df <- data.frame("c" = c, "x1" = x1, "x2" = x2)
df
# b
?svm
df${x1,x2}
df[, c("x1", "x2")]
df_x <- df[, c("x1", "x2")]
df_y <- df$c
svm(df_x, y = df_y, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
res <- svm(df_x, y = df_y, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
# c
res
# 10 support vectors
res$SV
res <- svm(x = df_x, y = df_y, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
res
res <- svm(df, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
res
res <- svm(data = df, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
res <- svm(df, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
res
res <- svm(df_x, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
res
res <- svm(x = df_x, y = df_y, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
res
df_x
df_y
df_y <- df[, "c"]
df_y
res <- svm(x = df_x, y = df_y, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
res
# Problem 1
# - a
c <- as.factor(c(rep(-1, times = 5), rep(1, times = 5)))
c
x1 <- c(1, 2, 4, 6, 8, 5, 7, 9, 12, 13)
x2 <- c(3, 1, 5, 9, 7, 1, 1, 4, 7, 6)
df <- data.frame("c" = c, "x1" = x1, "x2" = x2)
df_x <- df[, c("x1", "x2")]
df_y <- df$c
res <- svm(x = df_x, y = df_y, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
res
# - c
# 3 support vectors
res$SV
# - d
res$coefs
# - d
abs(res$coefs)
# - c
# 3 support vectors
res_svm$SV
res_svm <- svm(x = df_x, y = df_y, kernel = "linear", cost = 100000, scale = FALSE, tol = 0.00000001, shrinkage = FALSE)
# - c
# 3 support vectors
res_svm$SV
# x = (2,1)
# x = (8,7)
# x = (5,1)
res_svm$index
# - e
w <- lagrange * df_x[res_svm$index]
# - d
# 3 lagrange multipliers
lagrange <- abs(res_svm$coefs)
# - e
w <- lagrange * df_x[res_svm$index]
# - e
w <- lagrange * df_x[c(res_svm$index)]
# - e
df_x[res_svm$index]
# - e
res_svm$index
# - e
c(res_svm$index)
# - e
df_x[res_svm$index]
# - e
df_x[cres_svm$index]
# - e
df_x[,res_svm$index]
# - e
df_x[res_svm$index,]
w <- lagrange * df_x[SV_index,] * df_y[SV_index,]
# - e
SV_index <- res_svm$index
w <- lagrange * df_x[SV_index,] * df_y[SV_index,]
w <- lagrange * df_x[SV_index,] * df_y[SV_index,]
setwd("/media/matthieu/Data/Matthieu/##Etude/#M1/S2/TER/ter-sentiment-analysis")
library(aricode)
library(R.matlab)
library(skmeans)
library("FactoMineR")
library(NMF)
# ------- Dataset loading -------
#X <- readMat("mat_files/output_30.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_30.csv_bow.mat")
#X <- readMat("mat_files/output_not_original_30.csv_tf-idf.mat")
#X <- readMat("mat_files/output_not_original_30.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_50.csv_tf-idf-l2.mat")
X <- readMat("mat_files/output_not_original_10.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_5.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_no_clean.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_100.csv_tf-idf-l2.mat")
df <- X$X
#df
dim(df)
df
X
X
df
colnames(X)
colnames(df)
di(df)
dim(df)
dim(X)
setwd("/media/matthieu/Data/Matthieu/##Etude/#M1/S2/TER/ter-sentiment-analysis")
library(aricode)
library(R.matlab)
library(skmeans)
library("FactoMineR")
library(NMF)
# ------- Dataset loading -------
#X <- readMat("mat_files/output_30.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_30.csv_bow.mat")
#X <- readMat("mat_files/output_not_original_30.csv_tf-idf.mat")
#X <- readMat("mat_files/output_not_original_30.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_50.csv_tf-idf-l2.mat")
X <- readMat("mat_files/output_not_original_10.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_5.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_no_clean.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_100.csv_tf-idf-l2.mat")
df <- X$X
#df
dim(df)
