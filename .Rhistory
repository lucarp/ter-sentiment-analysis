install.packages("FactoMineR", dependencies = TRUE)
install.packages("xlsx", repos = "http://cran.cnr.Berkeley.edu/")
install.packages("xlsx", repos = "http://cran.cnr.Berkeley.edu/")
install.packages("FactoMineR", dependencies = TRUE)
install.packages("openxlsx", dependencies=TRUE)
install.packages("FactoMineR", dependencies = TRUE)
install.packages("openxlsx", dependencies=TRUE)
library(installr)
install.packages("installr")
install.packages('openxlsx', type='source', repos='http://cran.rstudio.com')
var(5,4)
var(c(5,4))
var(c(2,1,6,2,5,1,1,1,2,2,1,5,4,1,1,1,1,3))
sd(c(2,1,6,2,5,1,1,1,2,2,1,5,4,1,1,1,1,3))
mean(c(2,1,6,2,5,1,1,1,2,2,1,5,4,1,1,1,1,3))
sd(c(2,1,6,2,5,1,1,1,2,2,1,5,4,1,1,1,1,3))
median(c(2,1,6,2,5,1,1,1,2,2,1,5,4,1,1,1,1,3))
install.packages("NMF", dependencies = TRUE)
install.packages("skmeans", dependencies = TRUE)
library(skmeans)
library(NMF)
install.packages("NMF", dependencies = TRUE)
install.packages("NMF", dependencies = TRUE)
library(NMF)
install.packages("NMF", dependencies = TRUE)
install.packages("NMF", dependencies = TRUE)
install.packages("openssl", dependencies = TRUE)
install.packages("NMF", dependencies = TRUE)
install.packages("Rmpi", dependencies = TRUE)
install.packages("Biobase", dependencies = TRUE)
clear
clear()
install.packages("NMF", dependencies = TRUE)
install.packages("doMPI", dependencies = TRUE)
install.packages("Rmpi", dependencies = TRUE)
install.packages("Rmpi", dependencies = TRUE)
install.packages("NMF", dependa)
install.packages("Rmpi", dependencies = TRUE)
install.packages("NMF", dependencies = TRUE)
library("NMF")
library("skmeans")
install.extras('NMF')
library(pixmap)
read.pnm('MtRush.pgm')
matrix(1:27, nrow = 4, ncol = 4)
matrix(1:27, ncol = 5)
matrix(1:30, ncol = 5)
x <- matrix(1:30, ncol = 5)
x
nmf(x, 3)
res <- nmf(x, 3)
res
?nmf
res
res@fit
res@fit@W
res@fit@H
x
res <- nmf(x, 1)
res
res <- nmf(x, 5)
res
res@fit@W
res <- nmf(x, 3)
getwd()
readMat("sparse_data.mat")
library("matlab")
install.packages("matlab")
library(matlab)
install.packages("matlab", dependencies = TRUE)
install.packages("matlab", dependencies = TRUE)
library(matlab)
install.packages("R.matlab", dependencies = TRUE)
library(R.matlab)
readMat("sparse_data.mat")
x <- readMat("sparse_data.mat")
x
library(R.matlab)
readMat("sparse_data.mat")
x <- readMat("sparse_data.mat")
x
library(keras)
install.packages(keras, dependencies = TRUE)
install.packages("keras", dependencies = TRUE)
library(keras)
library(rARPACK) # to use SVDS
install.packages("rARPACK", dependencies = TRUE)
library(keras)
library(rARPACK) # to use SVDS
library(keras)
library(rARPACK) # to use SVDS
rm(list=ls())
mnist   = dataset_mnist()
install_keras()
mnist   = dataset_mnist()
x_train = mnist$train$x
y_train = mnist$train$y
x_test  = mnist$test$x
y_test  = mnist$test$y
# reshape & rescale
dim(x_train) = c(nrow(x_train), 784)
dim(x_test)  = c(nrow(x_test), 784)
x_train = x_train / 255
x_test = x_test / 255
mus = colMeans(x_train)
x_train_c =  sweep(x_train, 2, mus)
x_test_c =  sweep(x_test, 2, mus)
digitSVDS = svds(x_train_c, k = 2)
ZpcaTEST = x_test_c %*% digitSVDS$v # PCA projection of test data
model = keras_model_sequential()
model %>%
layer_dense(units = 512, activation = 'elu', input_shape = c(784)) %>%
layer_dense(units = 128, activation = 'elu') %>%
layer_dense(units = 2,   activation = 'linear', name = "bottleneck") %>%
layer_dense(units = 128, activation = 'elu') %>%
layer_dense(units = 512, activation = 'elu') %>%
layer_dense(units = 784, activation='sigmoid')
model %>% compile(
loss = loss_mean_squared_error, optimizer = optimizer_adam())
history = model %>% fit(verbose = 2, validation_data = list(x_test, x_test),
x_train, x_train, epochs = 5, batch_size = 128)
# Set the auto-encoder
autoencoder = keras_model(model$input, model$get_layer('bottleneck')$output)
ZencTEST = autoencoder$predict(x_test)  # bottleneck representation  of test data
par(mfrow=c(1,2))
myCols = colorRampPalette(c('green',     'red',  'blue',  'orange', 'steelblue2',
'darkgreen', 'cyan', 'black', 'grey',   'magenta') )
plot(ZpcaTEST[1:5000,], col= myCols(10)[(y_test+1)],
pch=16, xlab = 'Score 1', ylab = 'Score 2', main = 'PCA' )
legend( 'bottomright', col= myCols(10), legend = seq(0,9, by=1), pch = 16 )
plot(ZencTEST[1:5000,], col= myCols(10)[(y_test+1)],
pch=16, xlab = 'Score 1', ylab = 'Score 2', main = 'Autoencoder' )
legend( 'bottomleft', col= myCols(10), legend = seq(0,9, by=1), pch = 16 )
Renc = predict(model, x_test)        # autoencoder reconstruction
Rpca = sweep( ZpcaTEST %*% t(digitSVDS$v), 2, -mus) # PCA reconstruction
dev.off()
par(mfcol=c(3,9), mar = c(1, 1, 0, 0))
myGrays = gray(1:256 / 256)
for(u in seq_len(9) ){
image( matrix( x_test[u,], 28,28, byrow = TRUE)[,28:1], col = myGrays,
xaxt='n', yaxt='n')
image( matrix( Rpca[u,], 28,28, byrow = TRUE)[,28:1], col = myGrays ,
xaxt='n', yaxt='n')
image( matrix( Renc[u,], 28,28, byrow = TRUE)[,28:1], col = myGrays,
xaxt='n', yaxt='n')
}
history = model %>% fit(verbose = 2, validation_data = list(x_test, x_test),
x_train, x_train, epochs = 50, batch_size = 128)
# Set the auto-encoder
autoencoder = keras_model(model$input, model$get_layer('bottleneck')$output)
ZencTEST = autoencoder$predict(x_test)  # bottleneck representation  of test data
par(mfrow=c(1,2))
myCols = colorRampPalette(c('green',     'red',  'blue',  'orange', 'steelblue2',
'darkgreen', 'cyan', 'black', 'grey',   'magenta') )
plot(ZpcaTEST[1:5000,], col= myCols(10)[(y_test+1)],
pch=16, xlab = 'Score 1', ylab = 'Score 2', main = 'PCA' )
legend( 'bottomright', col= myCols(10), legend = seq(0,9, by=1), pch = 16 )
plot(ZencTEST[1:5000,], col= myCols(10)[(y_test+1)],
pch=16, xlab = 'Score 1', ylab = 'Score 2', main = 'Autoencoder' )
legend( 'bottomleft', col= myCols(10), legend = seq(0,9, by=1), pch = 16 )
Renc = predict(model, x_test)        # autoencoder reconstruction
Rpca = sweep( ZpcaTEST %*% t(digitSVDS$v), 2, -mus) # PCA reconstruction
# Experiment
kmeans(x_train)
# Experiment
kmeans(x_train, 10)
# Experiment
res <- kmeans(x_train, 10)
# Experiment
res <- kmeans(x_train, 10)
res
setwd("/media/matthieu/Data/Matthieu/##Etude/#M1/S2/TER/ter-sentiment-analysis")
# ------- Dataset loading -------
library(R.matlab)
#X <- readMat("mat_files/output_30.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_30.csv_bow.mat")
#X <- readMat("mat_files/output_not_original_30.csv_tf-idf.mat")
#X <- readMat("mat_files/output_not_original_30.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_50.csv_tf-idf-l2.mat")
X <- readMat("mat_files/output_not_original_10.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_5.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_no_clean.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_100.csv_tf-idf-l2.mat")
df <- X$X
#df
dim(df)
mat_df <- as.matrix(df)
dim(mat_df)
label <- read.csv("mat_files/dataset_LABEL.csv", header = FALSE)
# ------- Split, if wanted, per autor -------
# Get ID for each author
temp <- label$V1[1]
setwd("/media/matthieu/Data/Matthieu/##Etude/#M1/S2/TER/ter-sentiment-analysis")
# ------- Dataset loading -------
library(R.matlab)
#X <- readMat("mat_files/output_30.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_30.csv_bow.mat")
#X <- readMat("mat_files/output_not_original_30.csv_tf-idf.mat")
#X <- readMat("mat_files/output_not_original_30.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_50.csv_tf-idf-l2.mat")
X <- readMat("mat_files/output_not_original_10.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_5.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_no_clean.csv_tf-idf-l2.mat")
#X <- readMat("mat_files/output_not_original_100.csv_tf-idf-l2.mat")
df <- X$X
#df
dim(df)
mat_df <- as.matrix(df)
dim(mat_df)
label <- read.csv("mat_files/dataset_LABEL.csv", header = FALSE)
k <- 5
labelK <- apply(label, MARGIN = 1, FUN=function(x) max(1, ceiling(x*k))) # true label (1 to k)
# - K means clustering
res <- kmeans(df, centers = k)
length(res$cluster)
length(labelK)
# - Plot
layout(matrix(1:2))
plot(labelK)
plot(res$cluster)
# - K means clustering
res <- kmeans(df, centers = k)
res2$cluster
length(res$cluster)
length(labelK)
# - Plot
layout(matrix(1:2))
plot(labelK)
plot(res$cluster)
# - Compute NMI and ARI
# TODO - Do correclty the NMI and ARI (match cluster value with label value)
library(aricode)
NMI(res$cluster, labelK)
ARI(res$cluster, labelK)
# ------- Spherical K-means -------
library(skmeans)
res2 <- skmeans(df, k)
layout(matrix(1:2))
plot(labelK)
plot(res2$cluster)
res2 <- skmeans(df, k)
NMI(res2$cluster, labelK)
ARI(res2$cluster, labelK)
layout(matrix(1:2))
plot(labelK)
plot(res2$cluster)
# - K means clustering
res <- kmeans(df, centers = k)
# - Plot
layout(matrix(1:2))
plot(labelK)
plot(res$cluster)
# - K means clustering
res <- kmeans(df, centers = k)
# - Plot
layout(matrix(1:2))
plot(labelK)
plot(res$cluster)
NMI(res$cluster, labelK)
ARI(res$cluster, labelK)
# - K means clustering
res <- kmeans(df, centers = k)
# - Plot
layout(matrix(1:2))
plot(labelK)
plot(res$cluster)
# - K means clustering
res <- kmeans(df, centers = k)
# - Plot
layout(matrix(1:2))
plot(labelK)
plot(res$cluster)
# - K means clustering
res <- kmeans(df, centers = k)
# - Plot
layout(matrix(1:2))
plot(labelK)
plot(res$cluster)
NMI(res$cluster, labelK)
ARI(res$cluster, labelK)
ARI(labelK, labelK)
res$cluster
print(res$cluster)
labelK
res$cluster
temp <- res2$cluster
temp
replace(temp, temp==1, -1)
temp
replace(temp, temp==5, -1)
temp
temp <- res2$cluster
temp <- replace(temp, temp==5, -1)
temp <- replace(temp, temp==1, 5)
temp <- replace(temp, temp==-1, 1)
plot(temp)
plot(res2$cluster)
ARI(res2$cluster, labelK)
ARI(temp, labelK)
plot(labelK)
plot(res2$cluster)
svds(df)
