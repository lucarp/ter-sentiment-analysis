{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Sentiment Analysis of Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "TODO: Make this work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 17165\n"
     ]
    }
   ],
   "source": [
    "import import_reviews\n",
    "import preprocessing_tools\n",
    "\n",
    "## Import reviews from original dataset\n",
    "reviews, vocab = import_reviews.importDataset('dataset', 10)\n",
    "\n",
    "# TODO: Why is 'not' a stopword and why should it be removed from vocab? \n",
    "\n",
    "\n",
    "## Generate MAT files\n",
    "# print(\"save bow...\")\n",
    "# df, X = file_to_bow(sys.argv[1])\n",
    "# scipy.io.savemat(sys.argv[1]+\"_bow.mat\", {'X' : X})\n",
    "# print(\"save tf-idf...\")\n",
    "# df, X = file_to_tfidf(sys.argv[1])\n",
    "# scipy.io.savemat(sys.argv[1]+\"_tf-idf.mat\", {'X' : X})\n",
    "# print(\"save tf-idf with l2...\")\n",
    "# df, X = file_to_tfidf_l2(sys.argv[1])\n",
    "# scipy.io.savemat(sys.argv[1]+\"_tf-idf-l2.mat\", {'X' : X})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means, SK-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Building term x sentiment matrix\n",
    "\n",
    "Using external dataset [SentiWords 1.1](https://hlt-nlp.fbk.eu/technologies/sentiwords)\n",
    "\n",
    "[SentiWordNet 3.0](https://github.com/aesuli/sentiwordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentiWordNet v3.0.0 (1 June 2010)\n",
    "# Andrea Esuli\n",
    "#\n",
    "# SentiWordNet is distributed under the Attribution-ShareAlike 4.0 Unported (CC BY-SA 4.0) license.\n",
    "# http://creativecommons.org/licenses/by-sa/4.0/\n",
    "#\n",
    "# For any information about SentiWordNet:\n",
    "# Web: http://sentiwordnet.isti.cnr.it\n",
    "# -------\n",
    "#\n",
    "# Data format.\n",
    "#\n",
    "# SentiWordNet v3.0 is based on WordNet version 3.0.\n",
    "# WordNet website: http://wordnet.princeton.edu/\n",
    "#\n",
    "# The pair (POS,ID) uniquely identifies a WordNet (3.0) synset.\n",
    "# The values PosScore and NegScore are the positivity and negativity\n",
    "# score assigned by SentiWordNet to the synset.\n",
    "# The objectivity score can be calculated as:\n",
    "# ObjScore = 1 - (PosScore + NegScore)\n",
    "# SynsetTerms column reports the terms, with sense number, belonging\n",
    "# to the synset (separated by spaces).\n",
    "#\n",
    "# -------\n",
    "#\n",
    "# POS\tID\tPosScore\tNegScore\tSynsetTerms\tGloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "df=pd.read_csv('SentiWordNet_3.0.0.txt', sep='\\t', header=25)\n",
    "\n",
    "term_sentiment_matrix=[]\n",
    "for idx in range(df.shape[0]):\n",
    "    row = df.iloc[idx]\n",
    "    for word in row['SynsetTerms'].split(' '):\n",
    "        term_sentiment_matrix.append([word,row['PosScore'],row['NegScore']])\n",
    "\n",
    "pd.DataFrame(term_sentiment_matrix).to_csv('term_sentiment_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec and doc2vec\n",
    "\n",
    "\n",
    "Bibliography: \n",
    "\n",
    "-  [Word2Vec Udacity](https://github.com/udacity/deep-learning/blob/master/embeddings/Skip-Gram_word2vec.ipynb)\n",
    "-  [Polish sentiment analysis with Word2vec](https://ermlab.com/en/blog/nlp/polish-sentiment-analysis-using-keras-and-word2vec/)\n",
    "-  http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XI_DgxNKhTY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
