{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Sentiment Analysis of Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "TODO: Make this work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 17165\n"
     ]
    }
   ],
   "source": [
    "import import_reviews\n",
    "import preprocessing_tools\n",
    "\n",
    "## Import reviews from original dataset\n",
    "reviews, vocab = import_reviews.importDataset('dataset', 10)\n",
    "\n",
    "# TODO: Why is 'not' a stopword and why should it be removed from vocab? \n",
    "\n",
    "\n",
    "## Generate MAT files\n",
    "# print(\"save bow...\")\n",
    "# df, X = file_to_bow(sys.argv[1])\n",
    "# scipy.io.savemat(sys.argv[1]+\"_bow.mat\", {'X' : X})\n",
    "# print(\"save tf-idf...\")\n",
    "# df, X = file_to_tfidf(sys.argv[1])\n",
    "# scipy.io.savemat(sys.argv[1]+\"_tf-idf.mat\", {'X' : X})\n",
    "# print(\"save tf-idf with l2...\")\n",
    "# df, X = file_to_tfidf_l2(sys.argv[1])\n",
    "# scipy.io.savemat(sys.argv[1]+\"_tf-idf-l2.mat\", {'X' : X})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means, SK-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Building term x sentiment matrix\n",
    "\n",
    "Using external dataset [SentiWords 1.1](https://hlt-nlp.fbk.eu/technologies/sentiwords)\n",
    "\n",
    "[SentiWordNet 3.0](https://github.com/aesuli/sentiwordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentiWordNet v3.0.0 (1 June 2010)\n",
    "# Andrea Esuli\n",
    "#\n",
    "# SentiWordNet is distributed under the Attribution-ShareAlike 4.0 Unported (CC BY-SA 4.0) license.\n",
    "# http://creativecommons.org/licenses/by-sa/4.0/\n",
    "#\n",
    "# For any information about SentiWordNet:\n",
    "# Web: http://sentiwordnet.isti.cnr.it\n",
    "# -------\n",
    "#\n",
    "# Data format.\n",
    "#\n",
    "# SentiWordNet v3.0 is based on WordNet version 3.0.\n",
    "# WordNet website: http://wordnet.princeton.edu/\n",
    "#\n",
    "# The pair (POS,ID) uniquely identifies a WordNet (3.0) synset.\n",
    "# The values PosScore and NegScore are the positivity and negativity\n",
    "# score assigned by SentiWordNet to the synset.\n",
    "# The objectivity score can be calculated as:\n",
    "# ObjScore = 1 - (PosScore + NegScore)\n",
    "# SynsetTerms column reports the terms, with sense number, belonging\n",
    "# to the synset (separated by spaces).\n",
    "#\n",
    "# -------\n",
    "#\n",
    "# POS\tID\tPosScore\tNegScore\tSynsetTerms\tGloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "df=pd.read_csv('SentiWordNet_3.0.0.txt', sep='\\t', header=25)\n",
    "\n",
    "term_sentiment_matrix=[]\n",
    "for idx in range(df.shape[0]):\n",
    "    row = df.iloc[idx]\n",
    "    for word in row['SynsetTerms'].split(' '):\n",
    "        term_sentiment_matrix.append([word,row['PosScore'],row['NegScore']])\n",
    "\n",
    "pd.DataFrame(term_sentiment_matrix).to_csv('term_sentiment_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec and doc2vec\n",
    "\n",
    "\n",
    "Bibliography: \n",
    "\n",
    "-  [Word2Vec Udacity](https://github.com/udacity/deep-learning/blob/master/embeddings/Skip-Gram_word2vec.ipynb)\n",
    "-  [Polish sentiment analysis with Word2vec](https://ermlab.com/en/blog/nlp/polish-sentiment-analysis-using-keras-and-word2vec/)\n",
    "-  http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XI_DgxNKhTY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11790</td>\n",
       "      <td>Steve+Rhodes</td>\n",
       "      <td>0.1</td>\n",
       "      <td>twin surfer dude stew phil lay unconscious hos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17628</td>\n",
       "      <td>Steve+Rhodes</td>\n",
       "      <td>0.1</td>\n",
       "      <td>comedy funny matter hard try baby genius easil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18971</td>\n",
       "      <td>Steve+Rhodes</td>\n",
       "      <td>0.1</td>\n",
       "      <td>check watch frequently waiting something happe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28767</td>\n",
       "      <td>Steve+Rhodes</td>\n",
       "      <td>0.1</td>\n",
       "      <td>freddy got written directed star tom green wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3579</td>\n",
       "      <td>Steve+Rhodes</td>\n",
       "      <td>0.1</td>\n",
       "      <td>color night instant candidate worst movie list...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID        Author  Rating  \\\n",
       "0  11790  Steve+Rhodes     0.1   \n",
       "1  17628  Steve+Rhodes     0.1   \n",
       "2  18971  Steve+Rhodes     0.1   \n",
       "3  28767  Steve+Rhodes     0.1   \n",
       "4   3579  Steve+Rhodes     0.1   \n",
       "\n",
       "                                              Review  \n",
       "0  twin surfer dude stew phil lay unconscious hos...  \n",
       "1  comedy funny matter hard try baby genius easil...  \n",
       "2  check watch frequently waiting something happe...  \n",
       "3  freddy got written directed star tom green wor...  \n",
       "4  color night instant candidate worst movie list...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37453803, 38571680)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "list_of_lists = []\n",
    "for item in reviews['Review']:\n",
    "    list_of_lists.append(item.split(' '))\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "        list_of_lists,\n",
    "        size=150,\n",
    "        window=10,\n",
    "        min_count=2,\n",
    "        workers=10)\n",
    "\n",
    "model.train(list_of_lists, total_examples=len(list_of_lists), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.4447408616542816),\n",
       " ('frightening', 0.4160479009151459),\n",
       " ('chilling', 0.4063057005405426),\n",
       " ('bad', 0.3959125876426697),\n",
       " ('horrific', 0.39281484484672546),\n",
       " ('gory', 0.3784416615962982),\n",
       " ('violent', 0.37290963530540466),\n",
       " ('awful', 0.37238559126853943),\n",
       " ('ozus', 0.36093375086784363),\n",
       " ('would', 0.36067894101142883)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='horrible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11268256"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1='man',w2='bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
